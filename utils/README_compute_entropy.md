# æ™ºèƒ½å¤šå¡å¹¶è¡Œ Entropy è®¡ç®—

## ğŸ¯ æ–°ç‰¹æ€§

### è‡ªåŠ¨æ¨¡å‹ç±»å‹æ£€æµ‹

`compute_entropy_for_model()` ç°åœ¨èƒ½å¤Ÿ**è‡ªåŠ¨æ£€æµ‹**æ¨¡å‹ç±»å‹ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šï¼š

- âœ… **æ ‡å‡† Qwen æ¨¡å‹**: è‡ªåŠ¨ä½¿ç”¨ `AutoModelForCausalLM`
- âœ… **QwenBoost æ¨¡å‹**: è‡ªåŠ¨ä½¿ç”¨ `QwenBoostForCausalLM`
- âœ… **å®¹é”™æœºåˆ¶**: åŠ è½½å¤±è´¥è‡ªåŠ¨å›é€€åˆ°æ ‡å‡†æ¨¡å¼

### æ£€æµ‹é€»è¾‘

```python
def detect_model_type(model_path: str) -> str:
    """
    æ£€æµ‹è§„åˆ™ï¼š
    1. æ£€æŸ¥ config.json ä¸­çš„ ensemble_config / num_submodels å­—æ®µ
    2. æ£€æŸ¥ architectures ä¸­æ˜¯å¦åŒ…å« "Boost" / "Ensemble"
    3. æ£€æŸ¥æ˜¯å¦å­˜åœ¨ ensemble_weights.json ç­‰ç‰¹æœ‰æ–‡ä»¶
    4. é»˜è®¤è¿”å› "standard"
    """
```

## ğŸ“¦ API

### compute_entropy_for_model()

```python
from accelerate import PartialState
from utils.compute_entropy import compute_entropy_for_model

distributed_state = PartialState()

compute_entropy_for_model(
    model_path="path/to/model",           # æ¨¡å‹è·¯å¾„ï¼ˆè‡ªåŠ¨æ£€æµ‹ç±»å‹ï¼‰
    data_files=["data.jsonl"],            # æ•°æ®æ–‡ä»¶
    output_path="entropy_0.jsonl",        # è¾“å‡ºæ–‡ä»¶
    entropy_field="entropy_0",            # å­—æ®µå
    distributed_state=distributed_state,  # åˆ†å¸ƒå¼çŠ¶æ€
)
```

**æ³¨æ„**: ä¸å†éœ€è¦ `use_ensemble_model` å‚æ•°ï¼

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1: åœ¨è®­ç»ƒæµç¨‹ä¸­ï¼ˆè‡ªåŠ¨è°ƒç”¨ï¼‰

```bash
accelerate launch \
    --config_file=./scripts/accelerate_config.yaml \
    llmboost_train.py \
    --model-name "Qwen/Qwen2.5-3B" \
    --stage1-data-path "/path/to/data.jsonl" \
    --data-files "/path/to/data.jsonl" \
    --output-dir "./output"
```

### æ–¹æ³• 2: ç‹¬ç«‹æµ‹è¯•

```bash
# æµ‹è¯•æ ‡å‡† Qwen æ¨¡å‹
bash scripts/test_entropy_parallel.sh \
    "Qwen/Qwen2.5-3B" \
    "/path/to/data.jsonl" \
    "./test_entropy.jsonl" \
    8

# æµ‹è¯• QwenBoost æ¨¡å‹ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
bash scripts/test_entropy_parallel.sh \
    "path/to/qwen_boost_model" \
    "/path/to/data.jsonl" \
    "./test_entropy.jsonl" \
    8
```

### æ–¹æ³• 3: Python è„šæœ¬

```python
# test_my_model.py
from accelerate import PartialState
from utils.compute_entropy import compute_entropy_for_model

distributed_state = PartialState()

# è®¡ç®—ä»»ä½•æ¨¡å‹çš„ entropyï¼ˆè‡ªåŠ¨æ£€æµ‹ç±»å‹ï¼‰
compute_entropy_for_model(
    model_path="path/to/any/model",
    data_files=["data.jsonl"],
    output_path="entropy.jsonl",
    entropy_field="entropy_0",
    distributed_state=distributed_state,
)
```

è¿è¡Œï¼š
```bash
accelerate launch --num_processes 8 --multi_gpu test_my_model.py
```

## ğŸ” æ¨¡å‹ç±»å‹æ£€æµ‹ç¤ºä¾‹

### æ ‡å‡† Qwen æ¨¡å‹

```
[Rank 0] æ£€æµ‹åˆ°æ¨¡å‹ç±»å‹: standard
[Rank 0] ä½¿ç”¨ AutoModelForCausalLM åŠ è½½...
[Rank 0] æ¨¡å‹åŠ è½½å®Œæˆ (type=standard, vocab_size=151936, pad_token_id=151643)
```

### QwenBoost æ¨¡å‹

```
[Rank 0] æ£€æµ‹åˆ°æ¨¡å‹ç±»å‹: qwen_boost
[Rank 0] ä½¿ç”¨ QwenBoostForCausalLM åŠ è½½...
[Rank 0] æ¨¡å‹åŠ è½½å®Œæˆ (type=qwen_boost, vocab_size=151936, pad_token_id=151643)
```

### è‡ªåŠ¨å›é€€

```
[Rank 0] æ£€æµ‹åˆ°æ¨¡å‹ç±»å‹: qwen_boost
[Rank 0] ä½¿ç”¨ QwenBoostForCausalLM åŠ è½½...
[Rank 0] è­¦å‘Š: QwenBoostForCausalLM åŠ è½½å¤±è´¥ (module not found)ï¼Œå°è¯•ä½¿ç”¨æ ‡å‡†åŠ è½½æ–¹å¼...
[Rank 0] æ¨¡å‹åŠ è½½å®Œæˆ (type=standard, vocab_size=151936, pad_token_id=151643)
```

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†

### Pad Token é”™è¯¯ä¿®å¤

è‡ªåŠ¨ä¿®å¤ `AssertionError: Padding_idx must be within num_embeddings`ï¼š

```python
# 1. å…ˆåŠ è½½ tokenizerï¼Œè®¾ç½® pad_token
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.pad_token_id = tokenizer.eos_token_id

# 2. åŠ è½½æ¨¡å‹æ—¶æ˜ç¡®ä¼ å…¥ pad_token_id
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    pad_token_id=tokenizer.pad_token_id,  # â† å…³é”®
    ...
)

# 3. åŒæ­¥æ¨¡å‹é…ç½®
model.config.pad_token_id = tokenizer.pad_token_id
```

### æ¨¡å‹åŠ è½½å¤±è´¥è‡ªåŠ¨å›é€€

```python
try:
    # å°è¯•åŠ è½½ QwenBoost
    model = QwenBoostForCausalLM.from_pretrained(...)
except Exception as e:
    # å¤±è´¥åè‡ªåŠ¨å›é€€åˆ°æ ‡å‡†æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained(...)
    model_type = "standard"
```

## ğŸ“Š æ€§èƒ½

| GPUæ•°é‡ | æ•°æ®é‡ | æ ‡å‡†æ¨¡å‹æ—¶é—´ | QwenBoostæ—¶é—´ | åŠ é€Ÿæ¯” |
|---------|--------|--------------|---------------|--------|
| 1       | 10K    | ~60min       | ~65min        | 1.0x   |
| 8       | 10K    | ~8min        | ~9min         | 7.5x   |
| 8       | 100K   | ~80min       | ~90min        | 7.5x   |

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ï¼šæ£€æµ‹é”™è¯¯çš„æ¨¡å‹ç±»å‹

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥ `config.json` æ˜¯å¦æ­£ç¡®é…ç½®
- æ‰‹åŠ¨åœ¨ä»£ç ä¸­ä¿®æ”¹æ£€æµ‹é€»è¾‘
- æŸ¥çœ‹æ—¥å¿—ä¸­çš„ "æ£€æµ‹åˆ°æ¨¡å‹ç±»å‹" ä¿¡æ¯

### é—®é¢˜ï¼špad_token_id é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å·²è‡ªåŠ¨ä¿®å¤ï¼ŒæŸ¥çœ‹æ—¥å¿—ç¡®è®¤ï¼š
  ```
  [Rank 0] Tokenizer é…ç½®: vocab_size=151936, pad_token_id=151643
  ```

### é—®é¢˜ï¼šOOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å‡å°‘ GPU æ•°é‡
- å‡å° batch_sizeï¼ˆå½“å‰å›ºå®šä¸º1ï¼‰
- ä½¿ç”¨æ˜¾å­˜æ›´å¤§çš„ GPU

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0 (å½“å‰ç‰ˆæœ¬)

- âœ… è‡ªåŠ¨æ¨¡å‹ç±»å‹æ£€æµ‹
- âœ… ç§»é™¤ `use_ensemble_model` å‚æ•°
- âœ… æ™ºèƒ½åŠ è½½å’Œå›é€€æœºåˆ¶
- âœ… å¢å¼ºçš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—

### v1.0

- âœ… åŸºç¡€å¤šå¡å¹¶è¡ŒåŠŸèƒ½
- âœ… æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹ç±»å‹

## ğŸ“ æœ€ä½³å®è·µ

1. **æ€»æ˜¯ä½¿ç”¨å¤šå¡**: å³ä½¿æ•°æ®é‡å°ï¼Œå¤šå¡ä¹Ÿèƒ½æé€Ÿ
2. **æ£€æŸ¥æ—¥å¿—**: ç¡®è®¤æ£€æµ‹åˆ°æ­£ç¡®çš„æ¨¡å‹ç±»å‹
3. **ä¿ç•™ä¸´æ—¶æ–‡ä»¶**: å¦‚æœéœ€è¦è°ƒè¯•ï¼Œå¯ä»¥æ³¨é‡Šåˆ é™¤ä¸´æ—¶æ–‡ä»¶çš„ä»£ç 
4. **ç›‘æ§æ˜¾å­˜**: ä½¿ç”¨ `nvidia-smi` æˆ–è„šæœ¬ä¸­çš„æ˜¾å­˜æ‰“å°åŠŸèƒ½

## ğŸ“§ æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æŸ¥çœ‹å®Œæ•´æ—¥å¿—è¾“å‡º
2. ç¡®è®¤æ¨¡å‹ç±»å‹æ£€æµ‹æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥ pad_token_id é…ç½®
4. æŸ¥çœ‹ä¸Šè¿°æ•…éšœæ’é™¤éƒ¨åˆ†

