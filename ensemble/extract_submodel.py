#!/usr/bin/env python3
"""
ä»èåˆæ¨¡å‹ä¸­æå–æŒ‡å®šçš„å­æ¨¡å‹å¹¶ä¿å­˜ä¸ºç‹¬ç«‹æ¨¡å‹ã€‚

ç”¨æ³•:
    python extract_submodel.py --input <ensemble_model_path> --output <save_dir> [--submodel_idx 1] [--dtype bfloat16]

ç¤ºä¾‹:
    python extract_submodel.py \
        --input weights/llmboost/Qwen3-4B-Base/stage3_fused_brownboost/checkpoint-436 \
        --output weights/llmboost/Qwen3-4B-Base/stage3_m3 \
        --submodel_idx 1
"""

import os
import sys
import argparse

# å»¶è¿Ÿå¯¼å…¥ï¼Œå…ˆè§£æå‚æ•°ï¼ˆè¿™æ · --help å¯ä»¥åœ¨æ²¡æœ‰ä¾èµ–çš„æƒ…å†µä¸‹å·¥ä½œï¼‰
def import_dependencies():
    """å»¶è¿Ÿå¯¼å…¥ä¾èµ–"""
    import torch
    
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.pathï¼ˆçˆ¶ç›®å½•ï¼‰
    _current_dir = os.path.dirname(os.path.abspath(__file__))
    _parent_dir = os.path.dirname(_current_dir)  # é¡¹ç›®æ ¹ç›®å½•
    if _parent_dir not in sys.path:
        sys.path.insert(0, _parent_dir)
    
    # å¯¼å…¥ extract_submodel å‡½æ•°
    try:
        from utils.fuse_models import extract_submodel
        return extract_submodel, torch
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿:")
        print("  1. å·²æ¿€æ´»æ­£ç¡®çš„ conda ç¯å¢ƒï¼ˆä¾‹å¦‚: conda activate qwenï¼‰")
        print("  2. utils/ ç›®å½•å­˜åœ¨äºé¡¹ç›®æ ¹ç›®å½•")
        print(f"  3. å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        print(f"  4. è„šæœ¬ä½ç½®: {_current_dir}")
        print(f"  5. é¡¹ç›®æ ¹ç›®å½•: {_parent_dir}")
        print(f"  6. Python è·¯å¾„: {sys.path[:3]}")
        sys.exit(1)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ä»èåˆæ¨¡å‹ä¸­æå–æŒ‡å®šçš„å­æ¨¡å‹å¹¶ä¿å­˜ä¸ºç‹¬ç«‹æ¨¡å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æå– sub_models.1 (ç¬¬äºŒä¸ªæ¨¡å‹)
  python extract_submodel.py \\
      --input weights/llmboost/Qwen3-4B-Base/stage3_fused_brownboost/checkpoint-436 \\
      --output weights/llmboost/Qwen3-4B-Base/stage3_m3

  # æå– sub_models.0 (ç¬¬ä¸€ä¸ªæ¨¡å‹)
  python extract_submodel.py \\
      --input weights/llmboost/Qwen3-4B-Base/stage3_fused_brownboost/checkpoint-436 \\
      --output weights/llmboost/Qwen3-4B-Base/stage3_m0 \\
      --submodel_idx 0

  # æŒ‡å®šæ•°æ®ç±»å‹
  python extract_submodel.py \\
      --input weights/llmboost/Qwen3-4B-Base/stage3_fused_brownboost/checkpoint-436 \\
      --output weights/llmboost/Qwen3-4B-Base/stage3_m3 \\
      --dtype float16
        """
    )
    
    parser.add_argument(
        "--input",
        type=str,
        default="/root/buaa/czh/EnsembleLLM/weights/llmboost-code/Qwen3-8B-Base/stage3_fused_brownboost_freezefalse_vote-base/checkpoint-406",
        help="èåˆæ¨¡å‹è·¯å¾„ï¼ˆå¯ä»¥æ˜¯ checkpoint ç›®å½•æˆ–æ¨¡å‹ç›®å½•ï¼‰"
    )
    
    parser.add_argument(
        "--output",
        type=str,
        default="/root/buaa/czh/EnsembleLLM/weights/llmboost-code/Qwen3-8B-Base/stage3",
        help="ä¿å­˜æå–çš„å­æ¨¡å‹çš„ç›®å½•è·¯å¾„"
    )
    
    parser.add_argument(
        "--submodel_idx",
        type=int,
        default=1,
        help="è¦æå–çš„å­æ¨¡å‹ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€ä¸ªï¼Œ1è¡¨ç¤ºç¬¬äºŒä¸ªï¼Œé»˜è®¤: 1ï¼‰"
    )
    
    parser.add_argument(
        "--dtype",
        type=str,
        default="bfloat16",
        choices=["bfloat16", "float16", "float32"],
        help="ä¿å­˜çš„æƒé‡ç²¾åº¦ï¼ˆé»˜è®¤: bfloat16ï¼‰"
    )
    
    return parser.parse_args()


def get_torch_dtype(dtype_str: str, torch):
    """å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º torch dtype"""
    dtype_map = {
        "bfloat16": torch.bfloat16,
        "float16": torch.float16,
        "float32": torch.float32,
    }
    return dtype_map.get(dtype_str.lower(), torch.bfloat16)


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # å»¶è¿Ÿå¯¼å…¥ä¾èµ–ï¼ˆåœ¨è§£æå‚æ•°ä¹‹åï¼‰
    extract_submodel, torch = import_dependencies()
    
    # éªŒè¯è¾“å…¥è·¯å¾„
    if not os.path.exists(args.input):
        print(f"âŒ é”™è¯¯: è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ checkpoint ç›®å½•
    if os.path.isdir(args.input):
        # æ£€æŸ¥æ˜¯å¦æœ‰ config.json æˆ– pytorch_model.bin
        has_config = os.path.exists(os.path.join(args.input, "config.json"))
        has_model = os.path.exists(os.path.join(args.input, "pytorch_model.bin")) or \
                   any(f.startswith("pytorch_model") for f in os.listdir(args.input) if os.path.isfile(os.path.join(args.input, f)))
        
        if not (has_config or has_model):
            print(f"âš ï¸  è­¦å‘Š: è¾“å…¥ç›®å½•ä¼¼ä¹ä¸æ˜¯æœ‰æ•ˆçš„æ¨¡å‹ç›®å½•")
            print(f"   æœªæ‰¾åˆ° config.json æˆ– pytorch_model.bin")
            print(f"   ç»§ç»­å°è¯•åŠ è½½...")
    
    # è½¬æ¢ dtype
    torch_dtype = get_torch_dtype(args.dtype, torch)
    
    # æ‰“å°å‚æ•°ä¿¡æ¯
    print("=" * 60)
    print("ğŸ”¹ æå–å­æ¨¡å‹é…ç½®")
    print("=" * 60)
    print(f"  è¾“å…¥æ¨¡å‹: {args.input}")
    print(f"  è¾“å‡ºç›®å½•: {args.output}")
    print(f"  å­æ¨¡å‹ç´¢å¼•: {args.submodel_idx} (sub_models.{args.submodel_idx})")
    print(f"  æƒé‡ç²¾åº¦: {args.dtype}")
    print("=" * 60)
    print()
    
    # è°ƒç”¨ extract_submodel å‡½æ•°
    try:
        saved_path = extract_submodel(
            ensemble_model_path=args.input,
            submodel_idx=args.submodel_idx,
            save_dir=args.output,
            torch_dtype=torch_dtype
        )
        
        print()
        print("=" * 60)
        print("âœ… æå–å®Œæˆ!")
        print("=" * 60)
        print(f"  ä¿å­˜è·¯å¾„: {saved_path}")
        print(f"  è¾“å‡ºç›®å½•: {args.output}")
        print("=" * 60)
        
    except Exception as e:
        print()
        print("=" * 60)
        print(f"âŒ æå–å¤±è´¥: {e}")
        print("=" * 60)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

